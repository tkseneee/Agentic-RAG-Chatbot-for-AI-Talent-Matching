{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff5bf76-45f6-4b01-bbda-11162e947b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic RAG Chatbot with Memory is running! Type 'exit' to terminate.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  what are the top AI library or tool skills as per recent survey\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Based on the recent survey, the top AI libraries and tools include TensorFlow, PyTorch, Keras, Scikit-learn, and Pandas. These libraries and tools are widely used in the field of AI for various tasks such as data processing, model training, and deployment.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Which companies from my job folder need these skills?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Top Matched Companies:\n",
      "DeepAI_Solutions - Location: Bengaluru, India (Score: 0.7933)\n",
      "AutoAI_Systems - Location: Hyderabad, India (Score: 0.7899)\n",
      "VisionNext - Location: Hyderabad, India (Score: 0.7762)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Fetch me top candidates for this from our database.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: [{'name': 'Dr. Arjun Mehta', 'city': 'Bengaluru', 'skills': 'Python, TensorFlow, PyTorch, Kubernetes, AWS, GCP', 'email': 'arjun.mehta@aiworld.com', 'phone': '+91-9876543210', 'score': np.float64(0.8541), 'filename': 'Candidate_Summary_Arjun_Mehta.pdf'}, {'name': 'Dr. Neha Ramesh', 'city': 'Hyderabad', 'skills': 'Scikit-learn, XGBoost, Explainable AI (XAI), MLOps tools like MLflow', 'email': 'neha.ramesh@datainsights.com', 'phone': '+91-9123456780', 'score': np.float64(0.8263), 'filename': 'Candidate_Summary_Dr._Neha_Ramesh.pdf'}, {'name': 'Dr. T.K. Senthil Kumar', 'city': 'Chennai', 'skills': 'Artificial Intelligence, Machine Learning, Computer Vision, Deep Learning, Generative AI, MLOps', 'email': 'contact@gradascentglobal.com', 'phone': '9444700278', 'score': np.float64(0.8058), 'filename': 'Candidate_Summary_Dr_T_K_Senthil_Kumar.pdf'}]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Get me the full profile of Senthil\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Dr. T.K. Senthil Kumar is an accomplished AI educator and data science expert based in Chennai,\n",
      "India, with over 16 years of rich experience spanning both academia and industry. He is currently\n",
      "working as a Subject Matter Expert at L&T EduTech, where he plays a key role in developing\n",
      "curriculum and delivering hands-on sessions in Artificial Intelligence, Machine Learning, Computer\n",
      "Vision, Deep Learning, Generative AI, and MLOps. Prior to this, he served as a Data Scientist at\n",
      "NYBL, Dubai, specializing in computer vision model development for industrial applications. Dr.\n",
      "Senthil Kumar has also worked with leading EduTech firms like Great Learning and Manipal Global\n",
      "Education, mentoring industry professionals and academic learners alike. With a strong publication\n",
      "record, curriculum design expertise, and a passion for real-world AI deployment, he continues to\n",
      "bridge the gap between education and emerging technology. He is the co-founder of Grad Ascent\n",
      "Technologies, a startup focused on AI training and upskilling. He can be reached at 9444700278 or\n",
      "contact@gradascentglobal.com.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Can u search for his social media profile ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I found several social media profiles that could potentially belong to Dr. T.K. Senthil Kumar. Here are some of them:\n",
      "\n",
      "1. Instagram: Senthil Kumar (@dopkksenthilkumar) - Director of Photography, Oscar awards (Jury member)\n",
      "2. Instagram: Senthil Kumar T K (@tksenthilkumar)\n",
      "3. Facebook: DR.TK, Chennai, India. 2424 likes. They pave a way for Learning to all kind of people who are all interested to develop the Nation.\n",
      "\n",
      "Please note that these profiles may not necessarily belong to the same Dr. T.K. Senthil Kumar you are looking for, as there could be multiple individuals with the same name.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  I want his linkedin profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I found a LinkedIn profile that seems to match Dr. T.K. Senthil Kumar. The profile describes him as a Senior Data Scientist, Computer Vision Expert, AI & ML Educator, and Subject Matter Expert at L&T EduTech. He is also mentioned as a former Data Scientist at NYBL. Please note that LinkedIn profiles are not publicly accessible without an account, so you would need to search for his name on LinkedIn directly to view the full profile.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  Can u get his personal information from his online data ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: I'm sorry, but it's not appropriate or ethical to seek out or provide personal information about individuals without their consent. It's important to respect privacy and adhere to legal guidelines when using online data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import warnings\n",
    "from pymongo import MongoClient\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.agents import Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import ConversationalAgent, AgentExecutor\n",
    "\n",
    "# Suppress deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The method `Chain.run` was deprecated.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The method `Chain.__call__` was deprecated.*\")\n",
    "\n",
    "# Set API keys\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your_key\"\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"your_key\"\n",
    "\n",
    "# Tool 1: SERPAPI Tool\n",
    "search_tool = Tool(\n",
    "    name=\"Search Top Skills\",\n",
    "    func=SerpAPIWrapper().run,\n",
    "    description=\"Use this about the recent Survey.Use this to search the internet for recent or real-time information, such as LinkedIn profiles, company websites, news articles, or any online content the LLM can't answer directly\",\n",
    "    return_direct=False\n",
    ")\n",
    "\n",
    "# Tool 2: Document RAG Tool\n",
    "\n",
    "def embedding_based_job_description_rag(skills_query: str, folder='JobDescriptions', top_k=3):\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "    query_embedding = embedding_model.embed_query(skills_query)\n",
    "    matches = []\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            path = os.path.join(folder, filename)\n",
    "            with pdfplumber.open(path) as pdf:\n",
    "                content = \"\\n\".join([page.extract_text() or \"\" for page in pdf.pages])\n",
    "                if not content.strip():\n",
    "                    continue\n",
    "                content_embedding = embedding_model.embed_query(content)\n",
    "                similarity = cosine_similarity([query_embedding], [content_embedding])[0][0]\n",
    "                company = filename.replace(\".pdf\", \"\")\n",
    "                location = \"Not found\"\n",
    "                for line in content.split(\"\\n\"):\n",
    "                    if \"location\" in line.lower():\n",
    "                        location = line.strip()\n",
    "                        break\n",
    "                matches.append({\"company\": company, \"location\": location, \"score\": round(similarity, 4)})\n",
    "\n",
    "    matches.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    top_matches = matches[:top_k]\n",
    "    if not top_matches:\n",
    "        return \"No relevant companies found.\"\n",
    "    return \"Top Matched Companies:\\n\" + \"\\n\".join([f\"{m['company']} - {m['location']} (Score: {m['score']})\" for m in top_matches])\n",
    "\n",
    "document_rag_tool = Tool(\n",
    "    name=\"Job Description Matcher\",\n",
    "    func=embedding_based_job_description_rag,\n",
    "    description=\"Scans job description PDFs for companies needing given skills, and extracts location.\",\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "# Tool 3a: Candidate Matcher\n",
    "\n",
    "def fetch_best_matching_candidate(query: str, mongo_uri=\"mongodb://localhost:27017/\", db_name=\"documentDB\", collection_name=\"extracted_info\", top_k=3):\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    docs = list(collection.find({\"city_skill_embedding\": {\"$exists\": True}}))\n",
    "    if not docs:\n",
    "        return \"No embedded candidate data found.\"\n",
    "\n",
    "    embedding_model = OpenAIEmbeddings()\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "    similarities = []\n",
    "    for doc in docs:\n",
    "        score = cosine_similarity([query_embedding], [doc[\"city_skill_embedding\"]])[0][0]\n",
    "        similarities.append((score, doc))\n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "\n",
    "    top_matches = []\n",
    "    for score, doc in similarities[:top_k]:\n",
    "        top_matches.append({\n",
    "            \"name\": doc.get(\"name\"),\n",
    "            \"city\": doc.get(\"city\"),\n",
    "            \"skills\": doc.get(\"skills\"),\n",
    "            \"email\": doc.get(\"email\"),\n",
    "            \"phone\": doc.get(\"phone\"),\n",
    "            \"score\": round(score, 4),\n",
    "            \"filename\": doc.get(\"filename\")\n",
    "        })\n",
    "    return top_matches\n",
    "\n",
    "match_candidate_tool = Tool(\n",
    "    name=\"Candidate Matcher\",\n",
    "    func=lambda query: str(fetch_best_matching_candidate(query, top_k=3)),\n",
    "    description=\"Finds top 3 candidates matching skills and city using MongoDB embeddings.\",\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "# Tool 3b: Resume Fetcher\n",
    "\n",
    "def fetch_candidate_resume(filename: str, mongo_uri=\"mongodb://localhost:27017/\", db_name=\"documentDB\", collection_name=\"extracted_info\"):\n",
    "    client = MongoClient(mongo_uri)\n",
    "    db = client[db_name]\n",
    "    collection = db[collection_name]\n",
    "    doc = collection.find_one({\"filename\": filename})\n",
    "    if doc and \"raw_text\" in doc:\n",
    "        return doc[\"raw_text\"]\n",
    "    elif doc and \"content\" in doc:\n",
    "        return doc[\"content\"]\n",
    "    else:\n",
    "        return \"Resume content not found.\"\n",
    "\n",
    "resume_tool = Tool(\n",
    "    name=\"Candidate Resume Fetcher\",\n",
    "    func=fetch_candidate_resume,\n",
    "    description=\"Fetches the full resume of a candidate given their PDF filename.\",\n",
    "    return_direct=True\n",
    ")\n",
    "\n",
    "# Memory-aware agent setup\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4\")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent_chain = ConversationalAgent.from_llm_and_tools(\n",
    "    llm=llm,\n",
    "    tools=[search_tool, document_rag_tool, match_candidate_tool, resume_tool],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "agent = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent_chain,\n",
    "    tools=[search_tool, document_rag_tool, match_candidate_tool, resume_tool],\n",
    "    memory=memory,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Chatbot Interface\n",
    "\n",
    "def chatbot_agentic_rag():\n",
    "    print(\"Agentic RAG Chatbot with Memory is running! Type 'exit' to terminate.\")\n",
    "    while True:\n",
    "        user_query = input(\"You: \")\n",
    "        if user_query.strip().lower() == \"exit\":\n",
    "            print(\"Chatbot session terminated.\")\n",
    "            break\n",
    "        try:\n",
    "            response = agent.run(user_query)\n",
    "            print(f\"Bot: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot_agentic_rag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342563a9-ae7e-4b98-b185-3db1a66bf709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
